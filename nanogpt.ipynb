{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddeaaa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing\n",
    "import math\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9c951a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.5.1\n",
      "CUDA available: True\n",
      "CUDA version: 12.4\n",
      "Current device: 0\n",
      "Device name: NVIDIA GeForce RTX 3060\n"
     ]
    }
   ],
   "source": [
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA version:\", torch.version.cuda)\n",
    "print(\"Current device:\", torch.cuda.current_device() if torch.cuda.is_available() else \"N/A\")\n",
    "print(\"Device name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"N/A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c08afc0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print('Using CUDA')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('Using CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff01cbb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fe75eb01d90>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43875bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tiny-shakespeare.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd7cde1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115393"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cef510ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor citizens, the patricians good.\n",
      "What authority surfeits on would relieve us: if they\n",
      "would yield us but the superfluity, while it were\n",
      "wholesome, we might guess they relieved us humanely;\n",
      "but they think we are too dear: the leanness that\n",
      "afflicts us, the object of our misery, is as an\n",
      "inventory to particularise their abundance; our\n",
      "sufferance is a gain to them Let us revenge this with\n",
      "our pikes, ere we become rakes: for the gods know I\n",
      "speak this in hunger for bread, not in thirst for revenge.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92650a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "print(str().join(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36a123c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(chars)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f7f42f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\n': 0, ' ': 1, '!': 2, '$': 3, '&': 4, \"'\": 5, ',': 6, '-': 7, '.': 8, '3': 9, ':': 10, ';': 11, '?': 12, 'A': 13, 'B': 14, 'C': 15, 'D': 16, 'E': 17, 'F': 18, 'G': 19, 'H': 20, 'I': 21, 'J': 22, 'K': 23, 'L': 24, 'M': 25, 'N': 26, 'O': 27, 'P': 28, 'Q': 29, 'R': 30, 'S': 31, 'T': 32, 'U': 33, 'V': 34, 'W': 35, 'X': 36, 'Y': 37, 'Z': 38, 'a': 39, 'b': 40, 'c': 41, 'd': 42, 'e': 43, 'f': 44, 'g': 45, 'h': 46, 'i': 47, 'j': 48, 'k': 49, 'l': 50, 'm': 51, 'n': 52, 'o': 53, 'p': 54, 'q': 55, 'r': 56, 's': 57, 't': 58, 'u': 59, 'v': 60, 'w': 61, 'x': 62, 'y': 63, 'z': 64}\n"
     ]
    }
   ],
   "source": [
    "stoi = {ch: i for i, ch in enumerate(chars)}\n",
    "print(stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "786f9d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '\\n', 1: ' ', 2: '!', 3: '$', 4: '&', 5: \"'\", 6: ',', 7: '-', 8: '.', 9: '3', 10: ':', 11: ';', 12: '?', 13: 'A', 14: 'B', 15: 'C', 16: 'D', 17: 'E', 18: 'F', 19: 'G', 20: 'H', 21: 'I', 22: 'J', 23: 'K', 24: 'L', 25: 'M', 26: 'N', 27: 'O', 28: 'P', 29: 'Q', 30: 'R', 31: 'S', 32: 'T', 33: 'U', 34: 'V', 35: 'W', 36: 'X', 37: 'Y', 38: 'Z', 39: 'a', 40: 'b', 41: 'c', 42: 'd', 43: 'e', 44: 'f', 45: 'g', 46: 'h', 47: 'i', 48: 'j', 49: 'k', 50: 'l', 51: 'm', 52: 'n', 53: 'o', 54: 'p', 55: 'q', 56: 'r', 57: 's', 58: 't', 59: 'u', 60: 'v', 61: 'w', 62: 'x', 63: 'y', 64: 'z'}\n"
     ]
    }
   ],
   "source": [
    "itos = {i: ch for ch, i in stoi.items()}\n",
    "print(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db54d029",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(s: str) -> typing.List[int]:\n",
    "    return [stoi[c] for c in s]\n",
    "\n",
    "def decode(ints: typing.List[int]) -> str:\n",
    "    return str().join(itos[i] for i in ints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc9ee756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46, 43, 50, 50, 53, 1, 61, 53, 56, 50, 42]\n",
      "hello world\n"
     ]
    }
   ],
   "source": [
    "print(encode('hello world'))\n",
    "print(decode(encode('hello world')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e7aa338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115393"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text = encode(text)\n",
    "len(encoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03251ca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1115393])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.tensor(encoded_text, dtype=torch.long, device=device)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "596a940e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6bf5a201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
       "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
       "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
       "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
       "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
       "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
       "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
       "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
       "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
       "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n",
       "         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n",
       "        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n",
       "        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n",
       "         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n",
       "        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n",
       "        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n",
       "        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n",
       "        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n",
       "        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n",
       "        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n",
       "        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n",
       "         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n",
       "         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n",
       "         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n",
       "        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n",
       "        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n",
       "        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n",
       "        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n",
       "        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n",
       "        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n",
       "        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n",
       "         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n",
       "         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n",
       "        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n",
       "        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n",
       "        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n",
       "         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n",
       "        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n",
       "        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n",
       "         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n",
       "        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n",
       "        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n",
       "        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n",
       "        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n",
       "        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n",
       "        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n",
       "        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n",
       "        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n",
       "        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n",
       "         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n",
       "        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n",
       "        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n",
       "        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n",
       "        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n",
       "        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n",
       "        56, 43, 60, 43, 52, 45, 43,  8,  0,  0], device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fccf692f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size: 1003853, Validation size: 111540\n"
     ]
    }
   ],
   "source": [
    "n = int(0.9 * len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "print(f'Training size: {len(train_data)}, Validation size: {len(val_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da62e333",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 8 # Also called \"context length\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e474082c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58], device='cuda:0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c083096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- As characters ---\n",
      "When the input is F the next character is i\n",
      "When the input is Fi the next character is r\n",
      "When the input is Fir the next character is s\n",
      "When the input is Firs the next character is t\n",
      "When the input is First the next character is  \n",
      "When the input is First  the next character is C\n",
      "When the input is First C the next character is i\n",
      "When the input is First Ci the next character is t\n",
      "--- Encoded ---\n",
      "When the input is tensor([18], device='cuda:0') the next character is 47\n",
      "When the input is tensor([18, 47], device='cuda:0') the next character is 56\n",
      "When the input is tensor([18, 47, 56], device='cuda:0') the next character is 57\n",
      "When the input is tensor([18, 47, 56, 57], device='cuda:0') the next character is 58\n",
      "When the input is tensor([18, 47, 56, 57, 58], device='cuda:0') the next character is 1\n",
      "When the input is tensor([18, 47, 56, 57, 58,  1], device='cuda:0') the next character is 15\n",
      "When the input is tensor([18, 47, 56, 57, 58,  1, 15], device='cuda:0') the next character is 47\n",
      "When the input is tensor([18, 47, 56, 57, 58,  1, 15, 47], device='cuda:0') the next character is 58\n"
     ]
    }
   ],
   "source": [
    "xb = train_data[:block_size]\n",
    "yb = train_data[1:block_size+1]\n",
    "print('--- As characters ---')\n",
    "for t in range(block_size):\n",
    "    context = xb[:t+1]\n",
    "    target = yb[t]\n",
    "    print(f'When the input is {decode(context.tolist())} the next character is {itos[target.item()]}')\n",
    "print('--- Encoded ---')\n",
    "for t in range(block_size):\n",
    "    context = xb[:t+1]\n",
    "    target = yb[t]\n",
    "    print(f'When the input is {context} the next character is {target}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d6de2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(dataset: Tensor, batch_size: int, block_size: int, device=None) -> typing.Tuple[Tensor, Tensor]:\n",
    "    '''\n",
    "    Gets a batch of `batch_size` examples from `dataset`. Each example will\n",
    "    consist of `block_size` characters. The inputs and labels will both be\n",
    "    returned, both of which will be of size `(batch_size, block_size)`.\n",
    "    '''\n",
    "\n",
    "    ix = torch.randint(low=0, high=len(dataset)-block_size, size=(batch_size,), device=device)\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ebe5d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8])\n",
      "tensor([[35, 56, 43, 52, 41, 46,  1, 59],\n",
      "        [56, 50, 47, 49, 43,  1, 44, 39],\n",
      "        [13,  1, 50, 47, 58, 58, 50, 43],\n",
      "        [51,  6,  1, 47, 44,  1, 51, 63]], device='cuda:0')\n",
      "torch.Size([4, 8])\n",
      "tensor([[56, 43, 52, 41, 46,  1, 59, 54],\n",
      "        [50, 47, 49, 43,  1, 44, 39, 58],\n",
      "        [ 1, 50, 47, 58, 58, 50, 43,  1],\n",
      "        [ 6,  1, 47, 44,  1, 51, 63,  1]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "xb, yb = get_batch(train_data, batch_size=batch_size, block_size=block_size, device=device)\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print(yb.shape)\n",
    "print(yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7a43b7cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 0\n",
      "Block 0: When the input is tensor([35], device='cuda:0') the next character is 56\n",
      "Block 1: When the input is tensor([35, 56], device='cuda:0') the next character is 43\n",
      "Block 2: When the input is tensor([35, 56, 43], device='cuda:0') the next character is 52\n",
      "Block 3: When the input is tensor([35, 56, 43, 52], device='cuda:0') the next character is 41\n",
      "Block 4: When the input is tensor([35, 56, 43, 52, 41], device='cuda:0') the next character is 46\n",
      "Block 5: When the input is tensor([35, 56, 43, 52, 41, 46], device='cuda:0') the next character is 1\n",
      "Block 6: When the input is tensor([35, 56, 43, 52, 41, 46,  1], device='cuda:0') the next character is 59\n",
      "Block 7: When the input is tensor([35, 56, 43, 52, 41, 46,  1, 59], device='cuda:0') the next character is 54\n",
      "Example 1\n",
      "Block 0: When the input is tensor([56], device='cuda:0') the next character is 50\n",
      "Block 1: When the input is tensor([56, 50], device='cuda:0') the next character is 47\n",
      "Block 2: When the input is tensor([56, 50, 47], device='cuda:0') the next character is 49\n",
      "Block 3: When the input is tensor([56, 50, 47, 49], device='cuda:0') the next character is 43\n",
      "Block 4: When the input is tensor([56, 50, 47, 49, 43], device='cuda:0') the next character is 1\n",
      "Block 5: When the input is tensor([56, 50, 47, 49, 43,  1], device='cuda:0') the next character is 44\n",
      "Block 6: When the input is tensor([56, 50, 47, 49, 43,  1, 44], device='cuda:0') the next character is 39\n",
      "Block 7: When the input is tensor([56, 50, 47, 49, 43,  1, 44, 39], device='cuda:0') the next character is 58\n",
      "Example 2\n",
      "Block 0: When the input is tensor([13], device='cuda:0') the next character is 1\n",
      "Block 1: When the input is tensor([13,  1], device='cuda:0') the next character is 50\n",
      "Block 2: When the input is tensor([13,  1, 50], device='cuda:0') the next character is 47\n",
      "Block 3: When the input is tensor([13,  1, 50, 47], device='cuda:0') the next character is 58\n",
      "Block 4: When the input is tensor([13,  1, 50, 47, 58], device='cuda:0') the next character is 58\n",
      "Block 5: When the input is tensor([13,  1, 50, 47, 58, 58], device='cuda:0') the next character is 50\n",
      "Block 6: When the input is tensor([13,  1, 50, 47, 58, 58, 50], device='cuda:0') the next character is 43\n",
      "Block 7: When the input is tensor([13,  1, 50, 47, 58, 58, 50, 43], device='cuda:0') the next character is 1\n",
      "Example 3\n",
      "Block 0: When the input is tensor([51], device='cuda:0') the next character is 6\n",
      "Block 1: When the input is tensor([51,  6], device='cuda:0') the next character is 1\n",
      "Block 2: When the input is tensor([51,  6,  1], device='cuda:0') the next character is 47\n",
      "Block 3: When the input is tensor([51,  6,  1, 47], device='cuda:0') the next character is 44\n",
      "Block 4: When the input is tensor([51,  6,  1, 47, 44], device='cuda:0') the next character is 1\n",
      "Block 5: When the input is tensor([51,  6,  1, 47, 44,  1], device='cuda:0') the next character is 51\n",
      "Block 6: When the input is tensor([51,  6,  1, 47, 44,  1, 51], device='cuda:0') the next character is 63\n",
      "Block 7: When the input is tensor([51,  6,  1, 47, 44,  1, 51, 63], device='cuda:0') the next character is 1\n"
     ]
    }
   ],
   "source": [
    "for b in range(batch_size):\n",
    "    print(f'Example {b}')\n",
    "    for t in range(block_size):\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b, t]\n",
    "        print(f'Block {t}: When the input is {context} the next character is {target}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e1034574",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "    vocab_size: int\n",
    "    token_embedding_table: nn.Embedding\n",
    "\n",
    "    def __init__(self, vocab_size: int, device=None):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size, device=device)\n",
    "\n",
    "    def forward(self, idx: Tensor, targets: typing.Optional[Tensor] = None) -> typing.Tuple[Tensor, typing.Optional[Tensor]]:\n",
    "        # `idx` and targets are (B,T) tensors (batch size by time). In this case\n",
    "        # 'time' represents block size.\n",
    "        #\n",
    "        # `logits` are (B,T,C) tensors, (batch size by time by channel), where\n",
    "        # the channel dimension comes from the embedding table. Essentially,\n",
    "        # each character in idx is replaced by an embedding vector of length C\n",
    "        # (which is the vocabulary size in this case).\n",
    "        logits = self.token_embedding_table(idx)\n",
    "        logits = typing.cast(Tensor, logits)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "\n",
    "            logits = logits.view(B * T, C)\n",
    "            targets = targets.view(B * T)\n",
    "\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        # If `targets` was not provided, then output `logits` is a 3D tensor of\n",
    "        # shape:\n",
    "        #     `(batch_size, block_size, vocab_size)`\n",
    "        #\n",
    "        # Otherwise, if `targets` was provided, then output `logits` is a 2D\n",
    "        # tensor of shape:\n",
    "        #     `(batch_size * block_size, vocab_size)`\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx: Tensor, max_new_tokens: int) -> Tensor:\n",
    "        # `idx` is (B,T), which is `(batch_size, block_size)`\n",
    "        for _ in range(max_new_tokens):\n",
    "            # `logits` is (B,T,C), where C is the channel length (length of\n",
    "            # embedding vector, in this case it is `vocab_length`)\n",
    "            logits, loss = self(idx)\n",
    "            # Get last character of logits - becomes (B, C)\n",
    "            logits = logits[:, -1, :]\n",
    "            # Still (B,C)\n",
    "            probs = F.softmax(logits, dim=1)\n",
    "            # Now its (B,1) since we are getting only one sample\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            # Append sampled index to the running sequence - becomes (B,T+1)\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "        # The final `idx` tensor will be of shape\n",
    "        #     `(batch_size, block_size + max_steps)`\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "292fb53c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 65])\n",
      "tensor(4.5682, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = BigramLanguageModel(vocab_size, device=device)\n",
    "logits, loss = model(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "822c6f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "fCxBDkL-k\n",
      "zc.wfNZHxO Fn,yRtK\n",
      "axxP;CkPBbABXGeCXSvgO-3 SMmd?Ya3a\n",
      "hX:Y?XLtp&jjuHqUo,Kv.tbyr dXp!FZaLeWj\n"
     ]
    }
   ],
   "source": [
    "idx = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "next_idx = model.generate(idx, max_new_tokens=100)[0].tolist()\n",
    "next_str = decode(next_idx)\n",
    "print(next_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b039cdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss(model: BigramLanguageModel, train_dataset: Tensor, val_dataset: Tensor, eval_iterations: int, batch_size: int, block_size: int, device = None) -> typing.Dict[str, torch.types.Number]:\n",
    "    dataset_splits = {'train': train_dataset, 'val': val_dataset}\n",
    "    out = dict()\n",
    "    for split_name, split_dataset in dataset_splits.items():\n",
    "        losses = torch.zeros(eval_iterations, device=device)\n",
    "        for i in range(eval_iterations):\n",
    "            xb, yb = get_batch(split_dataset, batch_size, block_size, device)\n",
    "            logits, loss = model(xb, yb)\n",
    "            losses[i] = loss.item()\n",
    "        out[split_name] = losses.mean().item()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "863f2dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0      , last seen loss: 4.7392, estimated training loss: 4.6838, estimated validation loss: 4.6990\n",
      "Step: 40     , last seen loss: 4.6491, estimated training loss: 4.6359, estimated validation loss: 4.6494\n",
      "Step: 80     , last seen loss: 4.6633, estimated training loss: 4.5871, estimated validation loss: 4.5923\n",
      "Step: 120    , last seen loss: 4.5205, estimated training loss: 4.5382, estimated validation loss: 4.5428\n",
      "Step: 160    , last seen loss: 4.4845, estimated training loss: 4.4868, estimated validation loss: 4.5017\n",
      "Step: 200    , last seen loss: 4.4352, estimated training loss: 4.4415, estimated validation loss: 4.4558\n",
      "Step: 240    , last seen loss: 4.3763, estimated training loss: 4.3950, estimated validation loss: 4.4117\n",
      "Step: 280    , last seen loss: 4.3219, estimated training loss: 4.3519, estimated validation loss: 4.3666\n",
      "Step: 320    , last seen loss: 4.3645, estimated training loss: 4.3121, estimated validation loss: 4.3207\n",
      "Step: 360    , last seen loss: 4.2039, estimated training loss: 4.2743, estimated validation loss: 4.2888\n",
      "Step: 400    , last seen loss: 4.1740, estimated training loss: 4.2256, estimated validation loss: 4.2421\n",
      "Step: 440    , last seen loss: 4.2312, estimated training loss: 4.1892, estimated validation loss: 4.1967\n",
      "Step: 480    , last seen loss: 4.0490, estimated training loss: 4.1491, estimated validation loss: 4.1549\n",
      "Step: 520    , last seen loss: 4.1342, estimated training loss: 4.1017, estimated validation loss: 4.1142\n",
      "Step: 560    , last seen loss: 4.1009, estimated training loss: 4.0642, estimated validation loss: 4.0797\n",
      "Step: 600    , last seen loss: 4.0242, estimated training loss: 4.0279, estimated validation loss: 4.0388\n",
      "Step: 640    , last seen loss: 4.0363, estimated training loss: 3.9854, estimated validation loss: 4.0031\n",
      "Step: 680    , last seen loss: 4.0241, estimated training loss: 3.9533, estimated validation loss: 3.9642\n",
      "Step: 720    , last seen loss: 3.9811, estimated training loss: 3.9164, estimated validation loss: 3.9245\n",
      "Step: 760    , last seen loss: 3.9484, estimated training loss: 3.8796, estimated validation loss: 3.8883\n",
      "Step: 800    , last seen loss: 3.7964, estimated training loss: 3.8495, estimated validation loss: 3.8519\n",
      "Step: 840    , last seen loss: 3.7681, estimated training loss: 3.8136, estimated validation loss: 3.8240\n",
      "Step: 880    , last seen loss: 3.8023, estimated training loss: 3.7722, estimated validation loss: 3.7886\n",
      "Step: 920    , last seen loss: 3.6846, estimated training loss: 3.7486, estimated validation loss: 3.7549\n",
      "Step: 960    , last seen loss: 3.6881, estimated training loss: 3.7152, estimated validation loss: 3.7298\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "max_steps = 1000\n",
    "learning_rate = 1e-3\n",
    "eval_iterations = 300\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "model.train()\n",
    "\n",
    "for step in range(max_steps):\n",
    "    xb, yb = get_batch(train_data, batch_size=batch_size, block_size=block_size, device=device)\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    if max_steps < 25 or step % (max_steps // 25) == 0:\n",
    "        loss_dict = estimate_loss(model, train_data, val_data, eval_iterations, batch_size, block_size, device)\n",
    "        print(f'Step: {step:<7}, last seen loss: {loss.item():.4f}, estimated training loss: {loss_dict[\"train\"]:.4f}, estimated validation loss: {loss_dict[\"val\"]:.4f}')\n",
    "\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9fec8f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "F3GAbfin:F?z-TarAqwelsKath, tstVvpmXzeM?BIRo: \n",
      "adiWjhrtixOukevFrwlslji.Vy Ubruee:F'uHKdzva HNOwWtaPW&Itn,wmIpp\n",
      "PFMqQ\n",
      "&gxanu'oIV wQRaMEFahkHZy Tr Vl\n",
      "ikdrykff xjMuepI?KKJLey'stsuGFtvXop!G$L:yum:XFNy  w3noevCXXjPU? omYaVjAw.e  dx-I\n",
      "BAiERthDGINhMEsNAwhuHDwoG;G!gBADz.\n",
      "DYa\n",
      "EzFZvgEQRTA$NJo.HiurqUzrseCO \n",
      "qwHzxkO'NIaoW&xH:?zXrUMyme\n",
      "sREPw?zppW$Z taVL&d-PIUzMEhASChrd?O:oGPuq'xFovKUonGSBBkChDfYAsQkhfjj&aEfoh!qow3C;XqWBlcvHNmmvFZ&?$C,QKsz.fa?qpQD?Affoi\n",
      "LgQ3?JFrrCtgBO'GF:SrV\n",
      "h'gmes$BIVEcMvKaxx\n",
      "I!G\n",
      "K.-RP$z$sboTnoEReVsQCS?! Jmj&IxNI!qWGAynuHDqIire oFinJmN:pMcPN,fGSoda j&jJd'edS-EDsjZFe ms,C,y IbLhsZGV3 Tu.XLwWj&CSexGMpKNZvy,yumerDiZbbPY,Kri's'? -H ax,VlK$xILA-RUo FcpP'AfhPlad\n",
      "Eshr -EfC.ptCX:u,BX\n",
      "I&T:R'TXrutTvyolmxOmyW;llre,GFfCQxFq&jchDWi\n",
      "wndO?XGUtfC,R?vHD3LnohQju,wz.d?ZjFZzqWHr xke Tl;,KvWC&egW;fTndTuHvxaihkVvKXU,woFgiucd!p GAftW3?Ve\n",
      ":d;GaEFZai'3ogERbFy?zJN wmz:\n",
      "BBythN?NgaVGvpOE.!HAve vfhK?SffC'sb&BQkqglap..IW,foCe,KrdunheYbkDUNSrWB$.\n",
      "NSO:hNCSVR?ee poIVj;re-a;ZADgkDMENVcMqt3yresRKhraiuC.\n",
      "I.\n",
      "TSpJx-PA:\n"
     ]
    }
   ],
   "source": [
    "idx = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "next_idx = model.generate(idx, max_new_tokens=1000)[0].tolist()\n",
    "next_str = decode(next_idx)\n",
    "print(next_str)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_cuda12.2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
